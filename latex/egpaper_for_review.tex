\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{algorithm}% http://ctan.org/pkg/algorithm
\PassOptionsToPackage{noend}{algpseudocode}% comment out if want end's to show
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx


% \newcommand*{\algrule}[1][\algorithmicindent]{\makebox[#1][l]{\hspace*{.5em}\vrule height .75\baselineskip depth .25\baselineskip}}%

% \newcount\ALG@printindent@tempcnta
% \def\ALG@printindent{%
%     \ifnum \theALG@nested>0% is there anything to print
%         \ifx\ALG@text\ALG@x@notext% is this an end group without any text?
%             % do nothing
%             \addvspace{-3pt}% FUDGE for cases where no text is shown, to make the rules line up
%         \else
%             \unskip
%             % draw a rule for each indent level
%             \ALG@printindent@tempcnta=1
%             \loop
%                 \algrule[\csname ALG@ind@\the\ALG@printindent@tempcnta\endcsname]%
%                 \advance \ALG@printindent@tempcnta 1
%             \ifnum \ALG@printindent@tempcnta<\numexpr\theALG@nested+1\relax% can't do <=, so add one to RHS and use < instead
%             \repeat
%         \fi
%     \fi
%     }%
\usepackage{etoolbox}
% the following line injects our new indent handling code in place of the default spacing
% \patchcmd{\ALG@doentity}{\noindent\hskip\ALG@tlm}{\ALG@printindent}{}{\errmessage{failed to patch}}
% \makeatother
% end vertical rule patch for algorithmicx


% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

% \iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{mathrsfs}
\newcommand{\RED}[1]{#1}

\newcommand\TODO[1]{{\color{red}{TODO: #1}}}
\newcommand\UPDATE[1]{{\color{blue}{#1}}}
\newcommand\SOURCE[1]{{\color{green}{(from: #1)}}}
% \newcommand\CHANGED[2]{{{\color{blue}{#1}}\color{green}{#2}}}

\usepackage[dvipsnames]{xcolor}
\usepackage{enumitem}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi
\begin{document}

%%%%%%%%% TITLE
\title{\LaTeX\ Author Guidelines for ICCV Proceedings}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}


%%%%%%%%% ABSTRACT
\begin{abstract}
   The ABSTRACT is to be in fully-justified italicized text, at the top
   of the left-hand column, below the author and affiliation
   information. Use the word ``Abstract'' as the title, in 12-point
   Times, boldface type, centered relative to the column, initially
   capitalized. The abstract is to be in 10-point, single-spaced type.
   Leave two blank lines after the Abstract, then begin the main text.
   Look at previous ICCV abstracts to get a feel for style and length.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

\begin{itemize}
\item \textbf{Intro about CNN:} \textit{The successes of deep convolutional neural nets (CNNs) at image classiﬁcation has spawned a ﬂurry of work in computer vision on adapting these models to pixel-level image understanding tasks, such as boundary detection [1, 90, 64], semantic segmentation [60, 10, 46], optical ﬂow [87, 20], and pose estimation [85, 7].} \SOURCE{Rec. embeddings}
\item Intro about instance segmentation
\item \textbf{Mask R-CNN:} why we do not like it 
\begin{itemize}
\item \textit{most recent successful approaches to instance segmentation have adopted more heuristic approaches that first use an object detector to enumerate candidate instances and then perform pixel-level segmentation of each instance [57, 17, 55, 56, 2]. Alternately one can generate generic proposal segments and then label each one with a semantic detector [31, 12, 32, 16, 82, 34]. In either case the detection and segmentation steps can both be mapped to standard binary classiﬁcation losses. While effective, these approaches are somewhat unsatisfying since: (1) they rely on the object detector and non-maximum suppression heuristics to accurately “count” the number of instances, (2) they are difﬁcult to train in an end-to-end manner since the interface between instance segmentation and detection is non-differentiable, and (3) they underperform in cluttered scenes as the assignment of pixels to detections is carried out independently for each detection 1.} \SOURCE{Rec. embeddings}
\item elongated segments
\item \textit{There are three fundamental flaws in a proposal-based instance segmentation architecture. First, two objects may share the same bounding box, or a very similar boxes. In this case, the mask head, has no way of telling which object to pick in the box. This is a serious problem with stringy like object that have low fill rate in their bounding box (e.g. bicycles and chairs). Second, there is nothing in the architecture preventing a pixel to be shared between two instance. Third, the number of instances is limited by the number of proposals processed by the network (usually hundreds). More over, the architecture is complex and hard to tune and “debug”. In object detection, a precursor to this problem, there are already successes being made to use a simpler, single-stage, architectures e.g. RetinaNet.}
\end{itemize}

\item Briefly mention methods for proposal free (pixel embedding vectors, recurrent, more in related work)

\item Among successful methods: \textbf{predict short and long-range affinities}
\begin{itemize}
\item for each pixel we fix a set of neighboring pixels (not necessarily limited to the direct neighbors);  a CNN predicts then affinities, that represent how likely it is for each pair of neighboring pixels to be in the same instance.
\item The final segmentation is obtained by using some kind of graph clustering algorithm
\item \textbf{Motivation to use this method:} GMIS achieved comparable results to methods based on object proposal like Mask-R-CNN on natural images (Cityscapes);  MWS achieved SOA results on a biological images (ISBI)
\end{itemize}
\item It was shown that it is good to describe the problem in terms of a signed graph clustering problem (see MWS and others): directly train CNN to predict \textbf{repulsion and attraction}; no need to define seeds or to fix a threshold given an hierarchy of clusters, etc...


\item \textit{\textbf{Multicut} has the great advantage that a “natural” partitioning of a graph can be found, without needing to specify a desired number of clusters, or a termination criterion, or one seed per region. Its great drawback is that its optimization is NP-hard.} \SOURCE{MWS}.
\item Problem: this specific application is too expensive even for recently proposed multicut heuristics/ approximations
\item Efficient alternatives proposed independently (leave details to the related work), but: missing comparison on this type of problem/graph
\item our contributions:
\begin{itemize}
\item we propose a unified and simple formalization of Signed Graph Edge Contraction Clustering and show how many of the recently proposed methods can be seen as special cases
\item we compare different types of agglomeration clustering on a pixel grid graph with short and long-range connections, focusing on aspects like efficieny, robustness (and energy) 
\item we propose a new a constrained version of average agglomerative clustering that proved to be quite robust in most of our experiments
\end{itemize}
\item on other datasets (connectomics) many methods are based on multi-step pipelines first predicting superpixels
\item \textit{if we get decent scores on CREMI}: we show that also on neuro-data it is worth to skip the hand-crafted superpixel step and compute the final segmentation directly from the CNN predictions (MWS already showed it on ISBI)

\end{itemize}


\section{Related work}
\begin{itemize}
\item \textit{Optional:} more about \textbf{Mask R-CNN}? (we actually already explain in the introduction why we do not care about it)
\item \textbf{Proposal-free instance segmentation} methods:
\begin{itemize}
\item \textbf{Predict pixel embedding vectors:} 
\begin{itemize}
\item For each pixel in the image, a CNN predicts an embedding vector, such that pixels in the same instance are represented by the same vector. (\textit{by training a model that labels pixels with unit-length vectors that live in some ﬁxed dimension embedding space} \SOURCE{Rec. embeddings} ). \textit{With instance embedding, each object is assigned a “color” in a n-dimensional space. The network processes the image and produces a dense output, same size as the input image. Each pixel in the output of the network is a point in the embedding space. Pixels that belong to the same object are close in the embedding space while pixels that belong to different objects are distant in the embedding space. Parsing the image embedding space involves some sort of clustering algorithm.} \SOURCE{online} 
\item unsupervised or supervised; different types of loss \TODO{Find good summary}
\item clustering algorithms like DBSCAN, mean-shift or similar ones working directly in the embedding space  \TODO{Add refs, discuss with Roman}
\item \textit{Side comment}: Even with pixel embedding vectors we can deduce affinities or signed costs
\end{itemize}
\item \textbf{Other methods}: recurrent CNN, deep watershed, InstanceCut, Deep Coloring 2018 \TODO{Add more, discuss with Roman}
\item \textbf{Predicting long-range affinities:} superhuman, MWS, graph-merge on cityscapes, holistically edge detection (see MWS paper for a good review) \TODO{Add more}
\end{itemize}

\item So we need a \textbf{graph clustering algorithm}:
\begin{itemize}
\item Mention some seeded method?
\item \textit{Unsigned clustering methods:} Felzenszwalb Efficient Graph-based Image segmentation, (spectral clustering, graph cuts, not sure...)  \TODO{Here I need some input about recent stuff}
\item \textit{Merge-tree methods:} 
\begin{itemize}
\item Hierarchical clustering, ultra-metric contour map...? \TODO{This needs more research}
\item Only one from pixels I know: GMIS, hierarchical-Felzenszwalb (??) 
\item most of the others from superpixels
\item In connectomics: GALA, merge-mistakes (another section for splitting option?)
\item \textit{Similar to the boundary detection/region segmentation pipeline for natural image segmentation [6,7,8,9], most recent EM image segmentation methods use a membrane detection/cell segmentation pipeline. First, a membrane detector generates pixel-wise conﬁdence maps of membrane predictions using local image cues [10,11,12]. Next, region-based methods are applied to transforming the membrane conﬁdence maps into cell segments. It has been shown that region-based methods are necessary for improving the segmentation accuracy from membrane detections for EM images [13]. A common approach to region-based segmentation is to transform a membrane conﬁdence map into over-segmenting superpixels and use them as “building blocks” for ﬁnal segmentation. To correctly combine superpixels, greedy region agglomeration based on certain boundary saliency has been shown to work [14]. Meanwhile, structures, such as loopy graphs [15,16] or trees [17,18,19], are more often imposed to represent the region merging hierarchy and help transform the superpixel combination search into graph labeling problems. To this end, local [17,16] or structured [18,19] learning based methods are developed.} \SOURCE{SSHMT} \SOURCE{Jan Funke Multicut proposals}
\end{itemize}
\item \textbf{Signed graph}
\begin{itemize}
\item Multicut pipiline and heuristics
\item Jan Funke proposals
\item \textit{Cannot-link constraints:} initially introduced as hard-contraints, then relaxed (MWS, Greedy Fixation)
\item Local-search approximations of MC: GAEC, GreedyFixation
\end{itemize}
\end{itemize}

\end{itemize}




\begin{algorithm}
  \caption{Graph Agglomerative Clustering}
\setlength{\parindent}{\algorithmicindent} \textbf{Inputs:}
     \begin{itemize}[leftmargin=1.3cm,topsep=0.1pt,itemsep=-1.ex]
    %  \setlength\itemsep{0.em}
   \item $\mathcal{G}(V,E)$ with $|V|=N$, $|E|=M$
   \item signed edge weights $w:\,E\rightarrow\mathbb{R}$
   \item {\color{blue}addMustNotLink} $\in \{ True, False\}$
   \end{itemize}
   \vspace{0.4em}
   
\setlength{\parindent}{\algorithmicindent} \textbf{Output:} Final clustering $\Pi$

%   \hspace*{\algorithmicindent} \textbf{Inputs:} $\mathcal{G}(V,E)$ with signed costs $w:\,E\rightarrow\mathbb{R}$. \\
%   Prova \\
%   \hspace*{\algorithmicindent} \textbf{Outputs:} Final clustering $\Pi$\\

  \hspace*{\algorithmicindent} 
  \begin{algorithmic}[1]


    % \Procedure{GraphEdgeContr}{{\color{blue}bool \emph{addConstraints}}}
      % \State $\mathcal{G}'\gets \mathcal{G}(V,E^+ \cup E^-)$ \Comment{Initialize the contracted graph}
      \State $\mathcal{G}'(V', E') \gets \mathcal{G}(V, E)$  \Comment{Contracted graph}
    %   \State PQ $\gets$ Sort $e\in E$ in descending order of $|w_e|$
        \State PQ.push$(|w_e|, w_e, e) \quad \forall e \in E $  \Comment{Sort edges by $|w_e|$}
      
      \State $\Pi \gets \{ \{v_1\}, ..., \{v_N\} \}$ \Comment{Initial clustering}
      \State $E_\dagger \gets \{\}$ \Comment{Set of must-not-link edges}
    %   \State PQ.push$(e,  ) \quad \forall e \in E $  
    \State
      \While{PQ is \textbf{not} empty}
        \State $|\tilde{w}|, \tilde{w}, e_{uv} \gets $ PQ.popHighest()
        \If{ $e_{uv} \notin E' $} 
            \State \textbf{continue}
        \EndIf
        \If{({\color{ForestGreen}\textbf{$\tilde{w} > 0$}}) \textbf{and} ($e_{uv} \notin E_\dagger$)}
        %   \State $u,v \gets u,v \in V' : $
        %   \State $S_u \gets S \in \Pi$ : $ u \in S$
        %   \State $S_v \gets S \in \Pi$ : $ v \in S$
          \State PQ, $\,E_\dagger,\,\, E' \gets$ \textsc{deleteDoubleEdges}($u,v$)
        %   \State mergeDoubleEdges($u,v$) \Comment{Update PQ, $E_\dagger, \mathcal{G}'$}
          
        %   \State Update costs of double edges;
        %   \State Propagate constrained flags of double edges;
          \State $V' \gets V' \setminus \{ v\}$, $\quad E' \gets E' \setminus \{ e_{uv}\}$
        %   \State $ S_u \gets S_u \cup S_v$
          \State $\Pi \gets \Pi \cup \{ S_u^\Pi \cup S_v^\Pi \} \setminus \{ S_u^\Pi, S_v^\Pi \}$
          % \For{every new double edge}
          %   \State Delete double edges
          %   \State Insert new one with updated cost
          % \EndFor
        \EndIf
        \If{({\color{red}\textbf{$\tilde{w} \leq 0$}}) \textbf{and} {\color{blue}addMustNotLink}}
          \State $ E_\dagger \gets E_\dagger \cup \{e_{uv} \} $
        \EndIf
      \EndWhile
      \State
    %   \State
      \Return $\Pi$
      % \State
    % \EndProcedure

  \end{algorithmic}
  \hspace*{2cm} 
    \begin{algorithmic}[1]

    \Function{DeleteDoubleEdges}{$u,v$}
      % \State $\mathcal{G}'\gets \mathcal{G}(V,E^+ \cup E^-)$ \Comment{Initialize the contracted graph}
      \State $\mathcal{N}_u = \{ t \in V' | e_{ut}\in E'  \}$
      \State $\mathcal{N}_v = \{ t \in V' | e_{vt}\in E'  \}$
      \For{$t \in \mathcal{N}_u  \cap \mathcal{N}_v$ }
        \State $|\tilde{w}_1|, \tilde{w}_1, e_1 \gets $ PQ.pop($e_{ut}$)
        \State $|\tilde{w}_2|, \tilde{w}_2, e_2 \gets $ PQ.pop($e_{vt}$)
        % \State $e_1, e_2 \gets e_{ut}, e_{vt}$
        \State $E' \gets E' \setminus \{ e_2\}$ %\Comment{Delete double edge}
        \If{$e_2 \in E_\dagger $} \Comment{Propagate must-not-link}
            \State $ E_\dagger \gets E_\dagger \cup \{e_1 \} $
        \EndIf
        % \State $\tilde{w}_1, \tilde{w}_2 \gets $ PQ.pop($e_1$), PQ.pop($e_2$)
        \State $\tilde{w}_{\mathrm{new}} \gets$ \textsc{linkageCriteria}$(\tilde{w}_1, \tilde{w}_2)$
        \State PQ.push($|\tilde{w}_{\mathrm{new}}|$, $\tilde{w}_{\mathrm{new}}$,  $e_1$)
        
        
      \EndFor
      
      \State
    %   \State
      \Return PQ, $E_\dagger, E'$
    %   % \State


    \EndFunction

  \end{algorithmic}
  
\end{algorithm}



\section{Grand Unified Edge Contraction Algorithm}
\begin{itemize}
\item Define graph formalism
\item Rows in the table:
\begin{itemize}
\item Mutex Watershed (MWS), [proof of equivalence included in Appendix]
\item Greedy Additive Edge Contraction (GAEC), 
\item Greedy Fixation (GF), 
\item Hierarchical Agglomerative Clustering with single, complete, average (UPGMA) and weighted average (WPGMA) linkage criteria
\item GALA (learned update rule)
\item Something depending on the node size...?
\end{itemize}
\end{itemize}


\section{Experiments}
\begin{itemize}
\item Nevertheless, in both approaches we can define a grid graph (each vertex representing a pixel) with signed weights and find the final instance segmentation by using a graph partitioning algorithm:
\begin{itemize}
\item In Method 1, the graph is complete and the edge weights represent similarities between pairs of pixel embedding vectors. In most proposed approaches, embedding vectors representing distinct instances should be "distant enough" in the embedding space (a minimum distance is usually used during the training of the CNN). Thus, this threshold distance can be used to define signed affinities, representing attraction or repulsion between pairs of pixels;
\item  In Method 2, the short- and long-range affinities predicted by the CNN are directly used as signed edge weights in the grid graph
\end{itemize}
\end{itemize}

\subsection{Results summary}
\begin{itemize}
\item in the proposed simple formalism for Signed Graph Edge Contraction Clustering, we also include a modified version of Hierarchical agglomerative clustering with cannot-link constraints that was not mentioned in literature so far and in our experiments proved to be quite robust to noise and outliers
\item we compare different types of Signed Graph Edge Contraction Clustering, showing in which situations is preferable to use one or the other and which one can make a better use of the long-range CNN predictions; 
\item we focus our comparison on efficiency and robustness to mistakes in the CNN predictions 
\item in general, our experiments show that long-range predictions should be used not only during the CNN training, but also as an input of the clustering algorithm

\end{itemize}

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\section{Supplementary Material}
\begin{itemize}
\item Equivalence Mutex Watershed and Greedy Edge Contraction
\end{itemize}


\end{document}
