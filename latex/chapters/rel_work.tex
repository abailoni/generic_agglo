% !TEX root = ../agglo_clust_review.tex

\section{Related work}
\begin{itemize}
\item \textbf{Proposal based methods} 
\begin{itemize}
\item Generate region proposals or bounding boxes and classify the objects in the bounding box \cite{yang2012layered,ladicky2010and,hariharan2014simultaneous,chen2015multi,dai2016instance,liang2016reversible,he2017mask}; fully convolutional  box proposals \cite{li2017fully}. 
\item \emph{More references:} use an object detector to enumerate candidate instances and then perform pixel-level segmentation of each instance \cite{liang2018proposal,dai2016instance,li2017fully,liang2016reversible,arnab2017pixelwise} or generate generic proposal segments and then label each one with a semantic detector \cite{hariharan2014simultaneous,chen2015multi,hariharan2015hypercolumns,dai2015convolutional,uhrig2016pixel,he2017mask}.
% \SOURCE{\cite{kong2018recurrent}
\end{itemize}

\item \textbf{Other proposal-free methods:} 
\begin{itemize}
\item box-free \cite{pinheiro2015learning,pinheiro2016learning,liang2018proposal,hu2017fastmask}; joint segmentation and instance labeling jointly in a combinatorial framework \cite{kirillov2017instancecut}; recurrent models \cite{romera2016recurrent,ren2017end}
\item \textbf{Pixel embedding vectors}: supervised vectors \cite{bai2017deep,liu2017sgn}, unsupervised vectors  \cite{fathi2017semantic,newell2017associative,de2017semantic}, end-to-end training \cite{kong2018recurrent}, embedding depending on scene depth \cite{uhrig2016pixel}, TO CHECK: \cite{sironi2014multiscale}; \TODO{more on pose estimation, vector distance transform, deep coloring?, ECCV semi-convolutions}
% different types of loss
% \item For each pixel in the image, a CNN predicts an embedding vector, such that pixels in the same instance are represented by the same vector. (\textit{by training a model that labels pixels with unit-length vectors that live in some ﬁxed dimension embedding space} \SOURCE{Rec. embeddings} ). \textit{With instance embedding, each object is assigned a “color” in a n-dimensional space. The network processes the image and produces a dense output, same size as the input image. Each pixel in the output of the network is a point in the embedding space. Pixels that belong to the same object are close in the embedding space while pixels that belong to different objects are distant in the embedding space. Parsing the image embedding space involves some sort of clustering algorithm.} \SOURCE{online} 

% \item Clustering methods: DBSCAN, more

\item \textbf{Most related: predict short- and long-range affinities}. For each pixel we fix a set of neighboring pixels (not necessarily limited to the direct neighbors) and CNN predicts how likely it is for each pixel pair to be in the same instance \cite{liu2018affinity,wolf2018mutex,lee2017superhuman,xie2015holistically,Maire_2016_CVPR} 
% \item \cite{liu2018affinity} achieved comparable results to methods based on object proposal like Mask-R-CNN on natural images (Cityscapes); \cite{wolf2018mutex} achieved SOA results on a biological images (ISBI)
% \item Side comment: Even with pixel embedding vectors we can deduce affinities or signed costs
% (see MWS paper for a good review)

\end{itemize}



\item \textbf{Graph clustering related work}:
\begin{itemize}
\item Some seeded methods?
\item \textit{Unsigned clustering methods:} Efficient Graph-based Image segmentation \cite{felzenszwalb2004efficient}, old graph cut stuff: \cite{shi2000normalized} \TODO{More} 
 % (spectral clustering, graph cuts...)} 
\item \textit{Merge-tree methods:} 
\begin{itemize}
\item Hierarchical clustering, ultra-metric contour map \TODO{more}
\item Methods starting from pixels: \cite{liu2018affinity}, % check HIerarchical Felzenswalb
\item most of the others from superpixels
\item In connectomics: GALA, merge-mistakes (another section for splitting option?)
\item \textit{Similar to the boundary detection/region segmentation pipeline for natural image segmentation [6,7,8,9], most recent EM image segmentation methods use a membrane detection/cell segmentation pipeline. First, a membrane detector generates pixel-wise conﬁdence maps of membrane predictions using local image cues [10,11,12]. Next, region-based methods are applied to transforming the membrane conﬁdence maps into cell segments. It has been shown that region-based methods are necessary for improving the segmentation accuracy from membrane detections for EM images [13]. A common approach to region-based segmentation is to transform a membrane conﬁdence map into over-segmenting superpixels and use them as “building blocks” for ﬁnal segmentation. To correctly combine superpixels, greedy region agglomeration based on certain boundary saliency has been shown to work [14]. Meanwhile, structures, such as loopy graphs [15,16] or trees [17,18,19], are more often imposed to represent the region merging hierarchy and help transform the superpixel combination search into graph labeling problems. To this end, local [17,16] or structured [18,19] learning based methods are developed.} \SOURCE{SSHMT} \SOURCE{Jan Funke Multicut proposals}
\end{itemize}
\item \textbf{Signed graph}
\begin{itemize}
\item Multicut pipiline and heuristics
% \item \textit{\textbf{Multicut} has the great advantage that a “natural” partitioning of a graph can be found, without needing to specify a desired number of clusters, or a termination criterion, or one seed per region. Its great drawback is that its optimization is NP-hard.} \SOURCE{MWS}.

\item Jan Funke proposals
\item \textit{Must-not-link edges:} initially introduced as hard-constraints \cite{malmberg2011generalized}, then relaxed \cite{wolf2018mutex,levinkov2017comparative}
\item Local-search approximations of MC: greeedy fixation and greedy additive edge contraction \cite{levinkov2017comparative}
\end{itemize}
\end{itemize}

\end{itemize}

