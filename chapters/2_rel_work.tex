% !TEX root = ../agglo_clust_review.tex

\section{Related work} \label{sec:related_work}
% Recent progress in semantic segmentation \cite{long2015fully,kong2018recurrent,chen2018deeplab}, boundary detection \cite{arbelaez2011contour,xie2015holistically,maninis2018convolutional}, %, optical flow \cite{weinzaepfel2013deepflow,dosovitskiy2015flownet},
% and pose estimation \cite{wei2016convolutional,cao2017realtime} was mostly associated with new key ideas and architectures in deep learning, like dilated convolutions \cite{yu2015multi,chen2018deeplab} or ``hourglass'' architectures with skip connections \cite{ronneberger2015u,paszke2016enet} increasing the receptive field of view of the model.
\textbf{Proposal-based methods} have been highly successful in instance segmentation competitions like MS COCO \cite{lin2014microsoft}, Pascal VOC2012 \cite{everingham2010pascal} and CityScapes \cite{cordts2016cityscapes}. They decompose the instance segmentation task into two steps that consists in generating object proposals and assigning to each bounding box a class and a binary segmentation mask \cite{he2017mask,yang2012layered,li2017fully,ladicky2010and,hariharan2014simultaneous,chen2015multi,dai2016instance,liang2016reversible}. 
% Here I could have more: \cite{pinheiro2015learning,pinheiro2016learning,hu2017fastmask} and probably something more in Deep coloring
% \item \emph{More references:} or generate generic proposal segments and then label each one with a semantic detector \cite{hariharan2014simultaneous,chen2015multi,hariharan2015hypercolumns,dai2015convolutional,uhrig2016pixel,he2017mask}.
They commonly rely on {Faster-RCNN}~\cite{ren2015faster} and can be trained end-to-end using non-maximum suppression. Other methods use instead recurrent models to sequentially generate instances one-by-one \cite{romera2016recurrent,ren2017end}.

\textbf{Proposal-free methods} adopt a bottom-up approach by directly grouping pixels into instances. Recently, there has been a growing interest for such  methods that do not involve object detection, since, in certain types of data, object instances cannot be approximated by bounding boxes. For example, the approach proposed in \cite{kirillov2017instancecut} uses a combinatorial framework for instance segmentation; SGN \cite{liu2017sgn} sequentially group pixels into lines and then instances;
% encode instance relationships to classes and exploit the boundary information  \cite{jin2016object}; 
a watershed transform is learned in \cite{bai2017deep} by also predicting its gradient direction, whereas the template matching \cite{uhrig2016pixel} deploys scene depth information.
Others use metric learning to predict high-dimensional associative pixel embeddings that map pixels of the same instance close to each other, while mapping pixels belonging to different instances further apart \cite{fathi2017semantic,newell2017associative,de2017semantic,kulikov2018instance}. % Semi-convolutiona: \cite{novotny2018semi}
% \TODO{What about \cite{liang2018proposal} using spectral clustering?}. 
Final instances are then retrieved by applying a clustering algorithm, like in the end-to-end trainable mean-shift pipeline of \cite{kong2018recurrentPix}.
%  and introducing a Ô¨Åxed number of labels (colors) and then dynamically assigning object instances to those labels during training (coloring) \cite{kulikov2018instance}

\textbf{Edge detection} also experienced recent progress thanks to deep learning, both on natural images \cite{xie2015holistically,kokkinos2015pushing} and \UPDATE{biological data \cite{lee2017superhuman,schmidt2018cell,meirovitch2016multi,ciresan2012deep}}. In neuron segmentation for connectomics, a field of neuroscience we also address in our experiments, boundaries are converted to final instances with subsequent postprocessing and superpixel-merging:
% CNNs were introduced to this application in \cite{jain2007supervised}, but further progress in deep learning and 
% the introduction of new architectures lead to a much more refined boundary detection. 
% or trained an end-to-end watershed region growing algorithm \cite{wolf2017learned}.  
% Subsequent postprocessing and superpixel-merging outputs final instances. 
some use loopy graphs \cite{kaynig2015large,krasowski2015improving} or trees \cite{meirovitch2016multi,liu2016sshmt,liu2014modular,funke2015learning,uzunbas2016efficient} to represent the region merging hierarchy; the lifted multicut \cite{beier2017multicut} formulates the problem in a combinatorial framework, while flood-filling networks \cite{januszewski2018high} eliminate superpixels by training a recurrent CNN to perform region growing one region at the time. A structured learning approach was also proposed in \cite{funke2018large,turaga2009maximin}.
% \SOURCE{SSHMT} Check Funke proposals

\textbf{Agglomerative graph clustering} has often been applied to instance segmentation \cite{ren2013image,liu2016image,salembier2000binary}, because of its efficiency as compared to other top-down approaches like graph cuts. 
Novel termination criteria and merging strategies have often been proposed: the agglomeration in \cite{malmberg2011generalized} deploys fixed sets of merge constraints; ultrametric contour maps \cite{arbelaez2011contour} combine an oriented watershed transform with an edge detector, so that superpixels are merged until the ultrametric distance exceeds a learned threshold; the popular graph-based method \cite{felzenszwalb2004efficient} stops the agglomeration when the merge costs exceed a measure of quality for the current clusters. 
% \TODO{Roman, Cocoons, Benjamin?}
The optimization approach in \cite{kiran2014global} performs greedy merge decisions that minimize a certain energy, while other pipelines use classical HC linkage criteria, e.g. average linkage \cite{liu2018affinity,lee2017superhuman}, median \cite{funke2018large} or a linkage learned by a random forest classifier \cite{nunez2013machine,knowles2016rhoananet}.

\textbf{Clustering of signed graphs} has the goal of partitioning a graph with both attractive and repulsive cues. Finding an optimally balanced partitioning has a long history in combinatorial optimization \cite{grotschel1989cutting,grotschel1990facets,chopra1993partition}. %and can be done without the need to specify a termination criterion. 
NP-hardness of the \emph{correlation clustering} problem was shown in \cite{bansal2004correlation}, while the connection with graph multicuts was made by \cite{demaine2006correlation}. Modern integer linear programming solvers can tackle problems of considerable size \cite{andres2012globally}, but accurate approximations \cite{pape2017solving,beier2016efficient,yarkony2012fast}, greedy agglomerative algorithms \cite{levinkov2017comparative,wolf2018mutex,keuper2015efficient,kardoostsolving} and persistence criteria \cite{lange2018partial,lange2018combinatorial} have been proposed for even larger graphs.
% \TODO{Cannot-link constraints?}
% Missing: Funke proposals, discussion about cannot-link constraints!!!

This work reformulates the clustering algorithms of \cite{levinkov2017comparative,wolf2018mutex,keuper2015efficient} in a generalized framework and adopt ideas from the proposal-free methods \cite{liu2018affinity,wolf2018mutex,lee2017superhuman} to predict long-range relationships between pixels.
