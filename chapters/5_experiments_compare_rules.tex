% !TEX root = ../agglo_clust_review.tex


\begin{figure}
        \centering
\begin{minipage}[T]{0.48\textwidth}
% \begin{table}
    \centering
    \scriptsize
    % \begin{subtable}[t!]{0.5\textwidth}\centering
        \begin{tabular}{l|l|c}
        % \toprule
        % & \multicolumn{2}{c}{\thead{Add Cannot-Link Constraints:}} \\
         % & \multicolumn{1}{c}{\thead{\textsc{No}}} & \multicolumn{1}{c}{\thead{\textsc{Yes}}} \\ \midrule
         & \algname{} Linkage & \makecell{Arand-Score}  \\ \midrule \midrule
         % & \multicolumn{1}{c}{\thead{$\beta$}}  & \thead{AP} & \multicolumn{1}{c}{\thead{$\beta$}} & \thead{AP} \\ \midrule\midrule
\textbf{\algname{}} & \textbf{Average}& \textbf{0.936 $\pm$ 0.004}  \\
Greedy Fixation \cite{levinkov2017comparative} & Sum + Constr. & 0.906 $\pm$ 0.022 \\
DTWS + LMC (LR)& -& 0.903 $\pm$ 0.016 \\
DTWS + MC (LR)& -& 0.903 $\pm$ 0.017 \\
% DTWS + avgHC &-& \\
DTWS + MC (SR)& -& 0.900 $\pm$ 0.019 \\
DTWS + LMC (SR)& -& 0.898 $\pm$ 0.017 \\
Mutex Watershed \cite{wolf2018mutex} & Abs. Max.  & 0.897 $\pm$ 0.012 \\
GAEC \cite{keuper2015efficient} & Sum & 0.872 $\pm$ 0.028 \\
THRESH &-& 0.221  $\pm$ 0.067 \\ 
DTWS  & -& 0.010 $\pm$ 0.003\\
        \end{tabular}
    \captionof{table}{Arand-Scores and VI-Scores on CREMI challenge training data}
    \label{tab:results_cremi_train}
\end{minipage}\hfill
\begin{minipage}[T]{0.48\textwidth}
    \centering
    \scriptsize
        \begin{tabular}{l|c|c}
         & \makecell{CREMI \\Score} & \makecell{Arand\\Score} \\ \midrule
Our UNet + DTWS + LMC &  \textbf{0.221} & \textbf{0.108}\\
PNI-UNet & 0.228 & 0.116 \\
Our UNet + \algname{} Avg-Linkage & 0.244 & 0.130 \\
MALA-UNet + MC \cite{funke2018large} & 0.276 & 0.132 \\
CRUNet \cite{zeng2017deepem3d} & 0.566 & 0.229 \\
LFC \cite{parag2017anisotropic} & 0.616 & \\
        \end{tabular}
    \captionof{table}{\UPDATE{TBD:} Scores on test data}
    \label{tab:results_cremi_test}
\end{minipage}
\end{figure}

\subsection{CREMI Challenge} \label{sec:cremi_challenge}
We evaluate the algorithms in our framework on the competitive CREMI 2016 EM Segmentation Challenge \cite{cremiChallenge} that is currently the neuron segmentation challenge with the largest amount of training data available. The dataset comes from a serial section EM of \emph{Drosophila} fruit-fly tissue and consists of 6 volumes of 1250x1250x125 voxels at resolution 4x4x40nm, three of which present publicly available training ground truth. The results submitted to the leaderboard are evaluated using the CREMI score\footnote{\url{https://cremi.org/leaderboard/}}, based on the Adapted Rand-Score (Rand-Score) and the Variation of Information Score\cite{arganda2015crowdsourcing}. The data is highly anisotropic and contains artifacts like missing sections, staining precipitations and support film folds. 

\textbf{Training details}
To alleviate difficulties stemming from misalignment, we use a version of the data that was elastically realigned by the challenge organizers with the method of \cite{saalfeld2012elastic}.
We train a 3D U-Net \cite{ronneberger2015u, cciccek20163d} using the same architecture as \cite{funke2018large} and predict long-and-short range affinities 
as described in \cite{lee2017superhuman}. In addition to the standard data augmentation techniques of random rotations, random flips and  elastic deformations, we simulate data artifacts.
In more detail, we randomly zero-out slices, decrease the contrast of slices, simulate tears, introduce alignment jitter and paste artifacts extracted from the training data. Both \cite{funke2018large} and \cite{lee2017superhuman} have shown
that these kinds of augmentations can help to alleviate issues caused by EM-imaging artifacts.
We use L2 loss and Adam optimizer to train the network.
%\UPDATE{We pre-aligned the training and test data with an elastic alignment method \cite{saalfeld2012elastic}. We further simulated low contrast sections... and missing sections by setting their intensity value to zero... We used 3D U-Net architecture \cite{ronneberger2015u,cciccek20163d} trained with L1 loss (Adam optimizer with learning rate...).} 

\textbf{Additional methods tested }  We compare the performances of the algorithms in our framework with other basic and state-of-the-art post-processing methods. To ensure a fair comparison, we test all methods on the same predictions of our CNN model. As baseline methods, we consider a simple thresholding (THRESH) and a watershed algorithm seeded at the maxima of a boundary distance transform (WSDT). For these baselines, affinities are converted to a boundary map \UPDATE{by taking a weighted average over short- and long-range edge connections}. Other state-of-the-art multi-step-pipelines for neuron-segmentation first find 2D superpixels using WSDT and then apply a graph partitioning algorithm: in our comparison, we include one pipeline using agglomerative HC with average linkage (avgHC) and one using an approximation of the Lifted Multicut Problem (LMC) \cite{beier2016efficient}.


