% !TEX root = ../agglo_clust_review.tex

\captionsetup[subfigure]{justification=centering, singlelinecheck=off}
\begin{figure*}[t]
\centering
    \begin{subfigure}[t]{0.49 \textwidth}
        \centering
        \includegraphics[width=\textwidth,trim=0.55in 0.1in 0.65in 0.45in,clip]{./figs/noise_plots/under_segment_plots_0.pdf}
    \end{subfigure} \hfill
    \begin{subfigure}[t]{0.49 \textwidth}
        \centering
        \includegraphics[width=\textwidth,trim=0.53in 0.1in 0.65in 0.45in,clip]{./figs/noise_plots/under_segment_plots_1.pdf}
    \end{subfigure}

    %     \begin{subfigure}[t]{0.49 \textwidth}
    %     \centering
    %     \includegraphics[width=\textwidth,trim=0.53in 0.1in 0.65in 0.45in,clip]{./figs/noise_plots/over_segment_plots_0.pdf}
    %     \caption{No long-range predictions: \\$p_{\mathrm{long}}=0$} \label{fig:merge_noise_only_direct}
    % \end{subfigure} \hfill
    % \begin{subfigure}[t]{0.49 \textwidth}
    %     \centering
    %     \includegraphics[width=\textwidth,trim=0.53in 0.1in 0.65in 0.45in,clip]{./figs/noise_plots/over_segment_plots_1.pdf}
    %     \caption{With long-range predictions: $p_{\mathrm{long}}=0.1$} \label{fig:merge_noise_with_long_range}
    % \end{subfigure}
\caption{\algname{} sensitivity to noise: \emph{Average} linkage proved to be the most robust. Performances are given by Rand-Score (higher is better) depending on the amount of noise added to the CNN predictions. Solid lines represent median values over 30 experiments. Values between the 25th and the 75th percentile are shown in shaded areas. The two sets of experiments using under- and over-clustering noise are summarized in the plots at the top and at the bottom, respectively (see Appendix \ref{sec:appendix_noise_gen} for more details). For each experiment, some of the long-range CNN predictions were randomly selected with probability $p_{\mathrm{long}}$ and added as long-range edges to the pixel grid-graph. Experiments are performed on a crop of CREMI training sample B.
}\label{fig:noise_plots}
\end{figure*}
\begin{figure*}[t]
        \centering
\begin{minipage}[t]{0.48\textwidth}
    \centering
    \scriptsize
        \begin{tabular}[t]{l|c}
         Method & \makecell{CREMI-Score \\(lower is better)} \\ \midrule 
\textbf{\algname{}} \textbf{Average}& \textbf{0.226}  \\
\algname{} Sum + Constraints \cite{levinkov2017comparative} & 0.282 \\
\algname{} Abs. Max. \cite{wolf2018mutex} & 0.322 \\
\algname{} Max. + Constraints & 0.324 \\
\algname{} Sum \cite{keuper2015efficient} & 0.334 \\
\algname{} Average + Constraints & 0.563 \\
THRESH & 1.521 \\ 
        \end{tabular}
    \captionof{table}{CREMI-Scores achieved by different linkage criteria and thresholding. All methods use the affinity predictions from our CNN as input. Scores are averaged over the three CREMI training datasets.}
    \label{tab:results_cremi_train}
\end{minipage}\hfill
\begin{minipage}[t]{0.48\textwidth}
    \centering
    \scriptsize
        \begin{tabular}[t]{l|c}
        Method & \makecell{CREMI-Score \\(lower is better)}  \\ \midrule
Our CNN + DTWS + LMC &  0.221\\
PNI CNN \cite{lee2017superhuman} & 0.228 \\
\textbf{Our CNN + \algname{} Average} & \textbf{0.241} \\
MALA CNN + MC \cite{funke2018large} & 0.276 \\
CRU-Net \cite{zeng2017deepem3d} & 0.566  \\
LFC \cite{parag2017anisotropic} & 0.616  \\
        \end{tabular}
        \vspace*{0.99em}
    \captionof{table}{Current leading entries  in the CREMI challenge leaderboard \cite{cremiChallenge} (March 2020). All entries, apart from our using \algname{}, employ superpixel-based post-processing pipelines.}
    \label{tab:results_cremi_test}
\end{minipage}
\end{figure*}




\subsection{Data: CREMI challenge} \label{sec:cremi_challenge}
We evaluate all algorithms in the proposed framework on the competitive CREMI 2016 EM Segmentation Challenge \cite{cremiChallenge} that is currently the neuron segmentation challenge with the largest amount of training data available. The dataset comes from serial section EM of \emph{Drosophila} fruit-fly tissue and consists of 6 volumes of 1250x1250x125 voxels at resolution 4x4x40nm, three of which come with publicly available training ground truth. The results submitted to the leaderboard are evaluated using the CREMI score, based on the Adapted Rand-Score (Rand-Score) and the Variation of Information Score \cite{arganda2015crowdsourcing}. In Appendix \ref{sec:cremi_details}, we provide more details about the training of our CNN model, inspired by work of \cite{lee2017superhuman,funke2018large}.
